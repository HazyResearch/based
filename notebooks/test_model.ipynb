{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Run the setup.py in the based/ directory to install the package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Set to download to a path with sufficient space\n",
    "! export TRANSFORMERS_CACHE=/var/cr05_data/sim_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer_config.json: 100%|██████████| 26.0/26.0 [00:00<00:00, 5.07kB/s]\n",
      "config.json: 100%|██████████| 665/665 [00:00<00:00, 502kB/s]\n",
      "vocab.json: 100%|██████████| 1.04M/1.04M [00:00<00:00, 9.48MB/s]\n",
      "merges.txt: 100%|██████████| 456k/456k [00:00<00:00, 5.22MB/s]\n",
      "tokenizer.json: 100%|██████████| 1.36M/1.36M [00:00<00:00, 41.0MB/s]\n",
      "config.json: 100%|██████████| 2.86k/2.86k [00:00<00:00, 480kB/s]\n",
      "pytorch_model.bin: 100%|██████████| 1.45G/1.45G [00:03<00:00, 381MB/s] \n"
     ]
    }
   ],
   "source": [
    "# Step 3: Download the model\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "from based.models.gpt import GPTLMHeadModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "model = GPTLMHeadModel.from_pretrained_hf(\"hazyresearch/based-360m\").to(\"cuda\", dtype=torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTLMHeadModel(\n",
       "  (transformer): GPTModel(\n",
       "    (embeddings): GPT2Embeddings(\n",
       "      (word_embeddings): Embedding(50264, 1024)\n",
       "    )\n",
       "    (layers): ModuleList(\n",
       "      (0): Block(\n",
       "        (mixer): BaseConv(\n",
       "          (in_proj): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (out_proj): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "          (conv): ShortConvolution(\n",
       "            (conv): Conv1d(2048, 2048, kernel_size=(3,), stride=(1,), padding=(2,), groups=2048, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (dropout1): Dropout(p=0, inplace=False)\n",
       "        (drop_path1): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm1): RMSNorm()\n",
       "        (mlp): GatedMlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "          (fc2): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "        )\n",
       "        (dropout2): Dropout(p=0, inplace=False)\n",
       "        (drop_path2): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm2): RMSNorm()\n",
       "      )\n",
       "      (1): Block(\n",
       "        (mixer): LinearAttention(\n",
       "          (feature_map): TaylorExp()\n",
       "          (proj_q): Linear(in_features=1024, out_features=256, bias=False)\n",
       "          (proj_k): Linear(in_features=1024, out_features=256, bias=False)\n",
       "          (proj_v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (dropout1): Dropout(p=0, inplace=False)\n",
       "        (drop_path1): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm1): RMSNorm()\n",
       "        (mlp): GatedMlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "          (fc2): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "        )\n",
       "        (dropout2): Dropout(p=0, inplace=False)\n",
       "        (drop_path2): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm2): RMSNorm()\n",
       "      )\n",
       "      (2): Block(\n",
       "        (mixer): SlidingAttention(\n",
       "          (rotary_emb): RotaryEmbedding()\n",
       "          (Wqkv): FusedDense(in_features=1024, out_features=3072, bias=False)\n",
       "          (inner_attn): FlashSelfAttention(\n",
       "            (drop): Dropout(p=0, inplace=False)\n",
       "          )\n",
       "          (inner_cross_attn): FlashCrossAttention(\n",
       "            (drop): Dropout(p=0, inplace=False)\n",
       "          )\n",
       "          (out_proj): FusedDense(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (dropout1): Dropout(p=0, inplace=False)\n",
       "        (drop_path1): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm1): RMSNorm()\n",
       "        (mlp): GatedMlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "          (fc2): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "        )\n",
       "        (dropout2): Dropout(p=0, inplace=False)\n",
       "        (drop_path2): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm2): RMSNorm()\n",
       "      )\n",
       "      (3-5): 3 x Block(\n",
       "        (mixer): BaseConv(\n",
       "          (in_proj): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (out_proj): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "          (conv): ShortConvolution(\n",
       "            (conv): Conv1d(2048, 2048, kernel_size=(3,), stride=(1,), padding=(2,), groups=2048, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (dropout1): Dropout(p=0, inplace=False)\n",
       "        (drop_path1): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm1): RMSNorm()\n",
       "        (mlp): GatedMlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "          (fc2): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "        )\n",
       "        (dropout2): Dropout(p=0, inplace=False)\n",
       "        (drop_path2): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm2): RMSNorm()\n",
       "      )\n",
       "      (6): Block(\n",
       "        (mixer): LinearAttention(\n",
       "          (feature_map): TaylorExp()\n",
       "          (proj_q): Linear(in_features=1024, out_features=256, bias=False)\n",
       "          (proj_k): Linear(in_features=1024, out_features=256, bias=False)\n",
       "          (proj_v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (dropout1): Dropout(p=0, inplace=False)\n",
       "        (drop_path1): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm1): RMSNorm()\n",
       "        (mlp): GatedMlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "          (fc2): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "        )\n",
       "        (dropout2): Dropout(p=0, inplace=False)\n",
       "        (drop_path2): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm2): RMSNorm()\n",
       "      )\n",
       "      (7): Block(\n",
       "        (mixer): SlidingAttention(\n",
       "          (rotary_emb): RotaryEmbedding()\n",
       "          (Wqkv): FusedDense(in_features=1024, out_features=3072, bias=False)\n",
       "          (inner_attn): FlashSelfAttention(\n",
       "            (drop): Dropout(p=0, inplace=False)\n",
       "          )\n",
       "          (inner_cross_attn): FlashCrossAttention(\n",
       "            (drop): Dropout(p=0, inplace=False)\n",
       "          )\n",
       "          (out_proj): FusedDense(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (dropout1): Dropout(p=0, inplace=False)\n",
       "        (drop_path1): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm1): RMSNorm()\n",
       "        (mlp): GatedMlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "          (fc2): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "        )\n",
       "        (dropout2): Dropout(p=0, inplace=False)\n",
       "        (drop_path2): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm2): RMSNorm()\n",
       "      )\n",
       "      (8-10): 3 x Block(\n",
       "        (mixer): BaseConv(\n",
       "          (in_proj): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (out_proj): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "          (conv): ShortConvolution(\n",
       "            (conv): Conv1d(2048, 2048, kernel_size=(3,), stride=(1,), padding=(2,), groups=2048, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (dropout1): Dropout(p=0, inplace=False)\n",
       "        (drop_path1): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm1): RMSNorm()\n",
       "        (mlp): GatedMlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "          (fc2): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "        )\n",
       "        (dropout2): Dropout(p=0, inplace=False)\n",
       "        (drop_path2): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm2): RMSNorm()\n",
       "      )\n",
       "      (11): Block(\n",
       "        (mixer): LinearAttention(\n",
       "          (feature_map): TaylorExp()\n",
       "          (proj_q): Linear(in_features=1024, out_features=256, bias=False)\n",
       "          (proj_k): Linear(in_features=1024, out_features=256, bias=False)\n",
       "          (proj_v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (dropout1): Dropout(p=0, inplace=False)\n",
       "        (drop_path1): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm1): RMSNorm()\n",
       "        (mlp): GatedMlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "          (fc2): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "        )\n",
       "        (dropout2): Dropout(p=0, inplace=False)\n",
       "        (drop_path2): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm2): RMSNorm()\n",
       "      )\n",
       "      (12): Block(\n",
       "        (mixer): SlidingAttention(\n",
       "          (rotary_emb): RotaryEmbedding()\n",
       "          (Wqkv): FusedDense(in_features=1024, out_features=3072, bias=False)\n",
       "          (inner_attn): FlashSelfAttention(\n",
       "            (drop): Dropout(p=0, inplace=False)\n",
       "          )\n",
       "          (inner_cross_attn): FlashCrossAttention(\n",
       "            (drop): Dropout(p=0, inplace=False)\n",
       "          )\n",
       "          (out_proj): FusedDense(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (dropout1): Dropout(p=0, inplace=False)\n",
       "        (drop_path1): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm1): RMSNorm()\n",
       "        (mlp): GatedMlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "          (fc2): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "        )\n",
       "        (dropout2): Dropout(p=0, inplace=False)\n",
       "        (drop_path2): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm2): RMSNorm()\n",
       "      )\n",
       "      (13-15): 3 x Block(\n",
       "        (mixer): BaseConv(\n",
       "          (in_proj): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (out_proj): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "          (conv): ShortConvolution(\n",
       "            (conv): Conv1d(2048, 2048, kernel_size=(3,), stride=(1,), padding=(2,), groups=2048, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (dropout1): Dropout(p=0, inplace=False)\n",
       "        (drop_path1): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm1): RMSNorm()\n",
       "        (mlp): GatedMlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "          (fc2): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "        )\n",
       "        (dropout2): Dropout(p=0, inplace=False)\n",
       "        (drop_path2): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm2): RMSNorm()\n",
       "      )\n",
       "      (16): Block(\n",
       "        (mixer): LinearAttention(\n",
       "          (feature_map): TaylorExp()\n",
       "          (proj_q): Linear(in_features=1024, out_features=256, bias=False)\n",
       "          (proj_k): Linear(in_features=1024, out_features=256, bias=False)\n",
       "          (proj_v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (dropout1): Dropout(p=0, inplace=False)\n",
       "        (drop_path1): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm1): RMSNorm()\n",
       "        (mlp): GatedMlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "          (fc2): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "        )\n",
       "        (dropout2): Dropout(p=0, inplace=False)\n",
       "        (drop_path2): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm2): RMSNorm()\n",
       "      )\n",
       "      (17): Block(\n",
       "        (mixer): SlidingAttention(\n",
       "          (rotary_emb): RotaryEmbedding()\n",
       "          (Wqkv): FusedDense(in_features=1024, out_features=3072, bias=False)\n",
       "          (inner_attn): FlashSelfAttention(\n",
       "            (drop): Dropout(p=0, inplace=False)\n",
       "          )\n",
       "          (inner_cross_attn): FlashCrossAttention(\n",
       "            (drop): Dropout(p=0, inplace=False)\n",
       "          )\n",
       "          (out_proj): FusedDense(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (dropout1): Dropout(p=0, inplace=False)\n",
       "        (drop_path1): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm1): RMSNorm()\n",
       "        (mlp): GatedMlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "          (fc2): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "        )\n",
       "        (dropout2): Dropout(p=0, inplace=False)\n",
       "        (drop_path2): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm2): RMSNorm()\n",
       "      )\n",
       "      (18-20): 3 x Block(\n",
       "        (mixer): BaseConv(\n",
       "          (in_proj): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (out_proj): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "          (conv): ShortConvolution(\n",
       "            (conv): Conv1d(2048, 2048, kernel_size=(3,), stride=(1,), padding=(2,), groups=2048, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (dropout1): Dropout(p=0, inplace=False)\n",
       "        (drop_path1): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm1): RMSNorm()\n",
       "        (mlp): GatedMlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "          (fc2): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "        )\n",
       "        (dropout2): Dropout(p=0, inplace=False)\n",
       "        (drop_path2): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm2): RMSNorm()\n",
       "      )\n",
       "      (21): Block(\n",
       "        (mixer): LinearAttention(\n",
       "          (feature_map): TaylorExp()\n",
       "          (proj_q): Linear(in_features=1024, out_features=256, bias=False)\n",
       "          (proj_k): Linear(in_features=1024, out_features=256, bias=False)\n",
       "          (proj_v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (dropout1): Dropout(p=0, inplace=False)\n",
       "        (drop_path1): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm1): RMSNorm()\n",
       "        (mlp): GatedMlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "          (fc2): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "        )\n",
       "        (dropout2): Dropout(p=0, inplace=False)\n",
       "        (drop_path2): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm2): RMSNorm()\n",
       "      )\n",
       "      (22): Block(\n",
       "        (mixer): SlidingAttention(\n",
       "          (rotary_emb): RotaryEmbedding()\n",
       "          (Wqkv): FusedDense(in_features=1024, out_features=3072, bias=False)\n",
       "          (inner_attn): FlashSelfAttention(\n",
       "            (drop): Dropout(p=0, inplace=False)\n",
       "          )\n",
       "          (inner_cross_attn): FlashCrossAttention(\n",
       "            (drop): Dropout(p=0, inplace=False)\n",
       "          )\n",
       "          (out_proj): FusedDense(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (dropout1): Dropout(p=0, inplace=False)\n",
       "        (drop_path1): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm1): RMSNorm()\n",
       "        (mlp): GatedMlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "          (fc2): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "        )\n",
       "        (dropout2): Dropout(p=0, inplace=False)\n",
       "        (drop_path2): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm2): RMSNorm()\n",
       "      )\n",
       "      (23-26): 4 x Block(\n",
       "        (mixer): BaseConv(\n",
       "          (in_proj): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (out_proj): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "          (conv): ShortConvolution(\n",
       "            (conv): Conv1d(2048, 2048, kernel_size=(3,), stride=(1,), padding=(2,), groups=2048, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (dropout1): Dropout(p=0, inplace=False)\n",
       "        (drop_path1): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm1): RMSNorm()\n",
       "        (mlp): GatedMlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "          (fc2): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "        )\n",
       "        (dropout2): Dropout(p=0, inplace=False)\n",
       "        (drop_path2): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm2): RMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (drop_f): Dropout(p=0, inplace=False)\n",
       "    (ln_f): RMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=50264, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 4: Inspect the hybrid structure of Based\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "Stan -> ford\n",
      "ford ->  University\n",
      " university -> ,\n",
      " is ->  a\n",
      " in ->  the\n",
      " the ->  process\n",
      " state ->  of\n",
      " of ->  California\n"
     ]
    }
   ],
   "source": [
    "input = tokenizer(\"Stanford university is in the state of\", return_tensors=\"pt\").to(\"cuda\")\n",
    "output = model(**input)\n",
    "print(len(output.logits[0]))\n",
    "max = output.logits.argmax(dim=-1)[0]\n",
    "\n",
    "# next token predictions\n",
    "for tok, out_tok in zip(input[\"input_ids\"][0], max):\n",
    "    print(f\"{tokenizer.decode(tok.item())} -> {tokenizer.decode(out_tok.item())}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
